{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno_path_box = \"./dataset/Annotations/daySequence1/frameAnnotationsBOX.csv\"\n",
    "anno_path_bulb = \"./dataset/Annotations/daySequence1/frameAnnotationsBULB.csv\"\n",
    "frames_path = \"./dataset/daySequence1/frames/\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "with open(anno_path_box) as fp:  \n",
    "    line = fp.readline()\n",
    "    line = fp.readline() # Skip header line with descriptions\n",
    "\n",
    "    while line:\n",
    "        anno_file_path = (line.strip()).split(\";\")\n",
    "        anno_file_id = anno_file_path[0].split(\"/\")[1]\n",
    "        \n",
    "        file_name = os.path.join(os.path.join(frames_path, anno_file_id))\n",
    "        \n",
    "        anno_left = int(anno_file_path[2])\n",
    "        anno_top = int(anno_file_path[3])\n",
    "        anno_right = int(anno_file_path[4])\n",
    "        anno_bot = int(anno_file_path[5])\n",
    "        \n",
    "        file = cv2.imread(file_name)\n",
    "        file = cv2.cvtColor(file, cv2.COLOR_BGR2RGB);\n",
    "        crop = file[anno_top:anno_bot, anno_left:anno_right]\n",
    "        resized = cv2.resize(crop, (32, 64))\n",
    "        \n",
    "        images.append(resized)\n",
    "        labels.append(\n",
    "            {'go': 0,\n",
    "             'goLeft': 0,\n",
    "             'goForward': 0,\n",
    "             'warning': 1,\n",
    "             'warningLeft': 1,\n",
    "             'stop': 2,\n",
    "             'stopLeft': 2\n",
    "            }[anno_file_path[1]]\n",
    "        )\n",
    "        \n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(images), np.array(labels), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 5293\n",
      "Number of testing examples = 2607\n",
      "Image data shape = (64, 32, 3)\n",
      "Number of classes = 3\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import losses, optimizers, regularizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_labels = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 32, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "#Dropout(0.8)\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(MaxPooling2D(2,2))\n",
    "Dropout(0.5)\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4763 samples, validate on 530 samples\n",
      "Epoch 1/100\n",
      "4763/4763 [==============================] - 5s 1ms/step - loss: 2.1029 - acc: 0.8780 - val_loss: 1.2437 - val_acc: 0.9509\n",
      "Epoch 2/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 1.1356 - acc: 0.9561 - val_loss: 1.1788 - val_acc: 0.9509\n",
      "Epoch 3/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 1.0611 - acc: 0.9578 - val_loss: 1.1104 - val_acc: 0.9566\n",
      "Epoch 4/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 1.0070 - acc: 0.9609 - val_loss: 1.0746 - val_acc: 0.9547\n",
      "Epoch 5/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.9671 - acc: 0.9614 - val_loss: 1.0339 - val_acc: 0.9566\n",
      "Epoch 6/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.9416 - acc: 0.9603 - val_loss: 1.0075 - val_acc: 0.9566\n",
      "Epoch 7/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.9060 - acc: 0.9620 - val_loss: 0.9785 - val_acc: 0.9566\n",
      "Epoch 8/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.8797 - acc: 0.9620 - val_loss: 0.9544 - val_acc: 0.9566\n",
      "Epoch 9/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.8568 - acc: 0.9620 - val_loss: 0.9330 - val_acc: 0.9566\n",
      "Epoch 10/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.8364 - acc: 0.9620 - val_loss: 0.9138 - val_acc: 0.9566\n",
      "Epoch 11/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.8186 - acc: 0.9616 - val_loss: 0.9025 - val_acc: 0.9547\n",
      "Epoch 12/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.7662 - acc: 0.9213 - val_loss: 0.8501 - val_acc: 0.9377\n",
      "Epoch 13/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.4236 - acc: 0.9551 - val_loss: 0.2638 - val_acc: 0.9566\n",
      "Epoch 14/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.2493 - acc: 0.9616 - val_loss: 0.2392 - val_acc: 0.9566\n",
      "Epoch 15/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.2289 - acc: 0.9616 - val_loss: 0.2217 - val_acc: 0.9566\n",
      "Epoch 16/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.2116 - acc: 0.9618 - val_loss: 0.2054 - val_acc: 0.9566\n",
      "Epoch 17/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.2029 - acc: 0.9609 - val_loss: 0.1915 - val_acc: 0.9566\n",
      "Epoch 18/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.1836 - acc: 0.9633 - val_loss: 0.1780 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.1728 - acc: 0.9994 - val_loss: 0.1666 - val_acc: 0.9981\n",
      "Epoch 20/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.1656 - acc: 0.9977 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.1541 - acc: 0.9962 - val_loss: 0.2343 - val_acc: 0.9774\n",
      "Epoch 22/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.1654 - acc: 0.9859 - val_loss: 0.1417 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.1304 - acc: 0.9994 - val_loss: 0.1322 - val_acc: 0.9981\n",
      "Epoch 24/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.1183 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9981\n",
      "Epoch 25/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.1096 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9981\n",
      "Epoch 26/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.1011 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9981\n",
      "Epoch 27/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0939 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9981\n",
      "Epoch 28/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0871 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9981\n",
      "Epoch 29/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0727 - acc: 0.9998 - val_loss: 0.0633 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0585 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 0.9981\n",
      "Epoch 31/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9981\n",
      "Epoch 33/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0534 - acc: 0.9973 - val_loss: 0.0506 - val_acc: 0.9981\n",
      "Epoch 35/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0564 - acc: 0.9979 - val_loss: 0.0523 - val_acc: 0.9962\n",
      "Epoch 36/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0432 - acc: 0.9998 - val_loss: 0.0396 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0389 - acc: 0.9998 - val_loss: 0.0381 - val_acc: 0.9981\n",
      "Epoch 38/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0352 - acc: 0.9998 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9981\n",
      "Epoch 43/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0259 - acc: 0.9990 - val_loss: 0.0388 - val_acc: 0.9962\n",
      "Epoch 45/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.1263 - acc: 0.9859 - val_loss: 0.0613 - val_acc: 0.9962\n",
      "Epoch 46/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.1572 - acc: 0.9878 - val_loss: 0.3381 - val_acc: 0.9811\n",
      "Epoch 47/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.3920 - acc: 0.9698 - val_loss: 0.1876 - val_acc: 0.9925\n",
      "Epoch 48/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.1304 - acc: 0.9937 - val_loss: 0.1826 - val_acc: 0.9811\n",
      "Epoch 49/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.1199 - acc: 0.9929 - val_loss: 0.0833 - val_acc: 0.9981\n",
      "Epoch 50/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0810 - acc: 0.9975 - val_loss: 0.0730 - val_acc: 0.9981\n",
      "Epoch 51/100\n",
      "4763/4763 [==============================] - 1s 225us/step - loss: 0.0710 - acc: 0.9973 - val_loss: 0.0669 - val_acc: 0.9962\n",
      "Epoch 52/100\n",
      "4763/4763 [==============================] - 1s 226us/step - loss: 0.0634 - acc: 0.9975 - val_loss: 0.0572 - val_acc: 0.9981\n",
      "Epoch 53/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0560 - acc: 0.9983 - val_loss: 0.0568 - val_acc: 0.9962\n",
      "Epoch 54/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0539 - acc: 0.9987 - val_loss: 0.0474 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0479 - acc: 0.9990 - val_loss: 0.0452 - val_acc: 0.9981\n",
      "Epoch 56/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0432 - acc: 0.9990 - val_loss: 0.0393 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0389 - acc: 0.9992 - val_loss: 0.0373 - val_acc: 0.9981\n",
      "Epoch 58/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0355 - acc: 0.9996 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "4763/4763 [==============================] - 1s 226us/step - loss: 0.0330 - acc: 0.9996 - val_loss: 0.0349 - val_acc: 0.9981\n",
      "Epoch 60/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9981\n",
      "Epoch 61/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9981\n",
      "Epoch 62/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9981\n",
      "Epoch 63/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9981\n",
      "Epoch 64/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9981\n",
      "Epoch 69/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9981\n",
      "Epoch 72/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0186 - acc: 0.9990 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0210 - acc: 0.9985 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0153 - acc: 0.9998 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0652 - acc: 0.9950 - val_loss: 0.0327 - val_acc: 0.9981\n",
      "Epoch 76/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0253 - acc: 0.9992 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0195 - acc: 0.9990 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0163 - acc: 0.9996 - val_loss: 0.0155 - val_acc: 0.9981\n",
      "Epoch 79/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0145 - acc: 0.9996 - val_loss: 0.0162 - val_acc: 0.9981\n",
      "Epoch 80/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0129 - acc: 0.9998 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0117 - acc: 0.9998 - val_loss: 0.0129 - val_acc: 0.9981\n",
      "Epoch 82/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9981\n",
      "Epoch 83/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9981\n",
      "Epoch 84/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9981\n",
      "Epoch 85/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9981\n",
      "Epoch 86/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9962\n",
      "Epoch 87/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9981\n",
      "Epoch 88/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9962\n",
      "Epoch 89/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "Epoch 92/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "4763/4763 [==============================] - 1s 227us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.0094 - val_acc: 0.9981\n",
      "Epoch 95/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0092 - acc: 0.9994 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 96/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9981\n",
      "Epoch 97/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9981\n",
      "Epoch 98/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0068 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "4763/4763 [==============================] - 1s 228us/step - loss: 0.0168 - acc: 0.9979 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0333 - acc: 0.9952 - val_loss: 0.0283 - val_acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f485a70fc50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, categorical_labels, batch_size=64, epochs=100, verbose=True, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.024741279206932119, 0.99886642735688647]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, categorical_labels, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-605a5fb898e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traffic_light_classifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "model.save('traffic_light_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('traffic_light_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAD8CAYAAACchf2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nppp6CzlaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48584a2128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   2.35974833e-11,   9.00124972e-14]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "index = randint(1, len(X_train)) - 1\n",
    "img = X_train[index]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(y_train[index])\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDRPM7ZbjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f480e118e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'go': 0,\n",
       " 'goForward': 0,\n",
       " 'goLeft': 0,\n",
       " 'stop': 2,\n",
       " 'stopLeft': 2,\n",
       " 'warning': 1,\n",
       " 'warningLeft': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(labels, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "{'go': 0,\n",
    " 'goLeft': 0,\n",
    " 'goForward': 0,\n",
    " 'warning': 1,\n",
    " 'warningLeft': 1,\n",
    " 'stop': 2,\n",
    " 'stopLeft': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 2, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227.jpg\n",
      "[[  1.62554067e-10   1.00000000e+00   7.99638133e-11]]\n",
      "228.jpg\n",
      "[[  6.66529345e-14   1.00000000e+00   4.23909714e-13]]\n",
      "281.jpg\n",
      "[[  1.26009492e-09   8.65753440e-19   1.00000000e+00]]\n",
      "282.jpg\n",
      "[[  3.78886935e-26   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "images_carla = ['227.jpg', '228.jpg', '281.jpg', '282.jpg']\n",
    "\n",
    "for current_image in images_carla:\n",
    "    file_440 = cv2.imread(current_image)\n",
    "    file_440 = cv2.cvtColor(file_440, cv2.COLOR_BGR2RGB);\n",
    "    resized_440 = cv2.resize(file_440, (32, 64))\n",
    "\n",
    "    resized_440 = np.array(resized_440)\n",
    "\n",
    "    x_440 = image.img_to_array(resized_440)\n",
    "    x_440 = np.expand_dims(x_440, axis=0)\n",
    "\n",
    "    print(current_image)\n",
    "    print(loaded_model.predict(x_440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
