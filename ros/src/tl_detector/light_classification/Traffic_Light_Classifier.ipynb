{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno_path_box = \"./dataset/Annotations/daySequence1/frameAnnotationsBOX.csv\"\n",
    "anno_path_bulb = \"./dataset/Annotations/daySequence1/frameAnnotationsBULB.csv\"\n",
    "frames_path = \"./dataset/daySequence1/frames/\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "with open(anno_path_box) as fp:  \n",
    "    line = fp.readline()\n",
    "    line = fp.readline() # Skip header line with descriptions\n",
    "\n",
    "    while line:\n",
    "        anno_file_path = (line.strip()).split(\";\")\n",
    "        anno_file_id = anno_file_path[0].split(\"/\")[1]\n",
    "        \n",
    "        file_name = os.path.join(os.path.join(frames_path, anno_file_id))\n",
    "        \n",
    "        anno_left = int(anno_file_path[2])\n",
    "        anno_top = int(anno_file_path[3])\n",
    "        anno_right = int(anno_file_path[4])\n",
    "        anno_bot = int(anno_file_path[5])\n",
    "        \n",
    "        file = cv2.imread(file_name)\n",
    "        file = cv2.cvtColor(file, cv2.COLOR_BGR2RGB);\n",
    "        crop = file[anno_top:anno_bot, anno_left:anno_right]\n",
    "        resized = cv2.resize(crop, (32, 64))\n",
    "        \n",
    "        images.append(resized)\n",
    "        labels.append(\n",
    "            {'go': 0,\n",
    "             'goLeft': 0,\n",
    "             'goForward': 0,\n",
    "             'warning': 1,\n",
    "             'warningLeft': 1,\n",
    "             'stop': 2,\n",
    "             'stopLeft': 2\n",
    "            }[anno_file_path[1]]\n",
    "        )\n",
    "        \n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(images), np.array(labels), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 5293\n",
      "Number of testing examples = 2607\n",
      "Image data shape = (64, 32, 3)\n",
      "Number of classes = 3\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import losses, optimizers, regularizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_labels = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 32, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "#Dropout(0.8)\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(MaxPooling2D(2,2))\n",
    "Dropout(0.5)\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4763 samples, validate on 530 samples\n",
      "Epoch 1/100\n",
      "4763/4763 [==============================] - 1s 283us/step - loss: 2.9407 - acc: 0.8511 - val_loss: 2.3516 - val_acc: 0.8887\n",
      "Epoch 2/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 1.3578 - acc: 0.9425 - val_loss: 0.5656 - val_acc: 0.9566\n",
      "Epoch 3/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.4689 - acc: 0.9954 - val_loss: 0.4202 - val_acc: 0.9981\n",
      "Epoch 4/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.3882 - acc: 0.9994 - val_loss: 0.3577 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.3383 - acc: 0.9981 - val_loss: 0.3127 - val_acc: 0.9981\n",
      "Epoch 6/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.2937 - acc: 0.9981 - val_loss: 0.2715 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2529 - acc: 0.9998 - val_loss: 0.2349 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2201 - acc: 0.9998 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1922 - acc: 0.9998 - val_loss: 0.1794 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1678 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1470 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2524 - acc: 0.9864 - val_loss: 0.1837 - val_acc: 0.9981\n",
      "Epoch 13/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1673 - acc: 0.9971 - val_loss: 0.1484 - val_acc: 0.9981\n",
      "Epoch 14/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1761 - acc: 0.9958 - val_loss: 0.1344 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.1346 - acc: 0.9985 - val_loss: 0.1170 - val_acc: 0.9981\n",
      "Epoch 16/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1109 - acc: 0.9990 - val_loss: 0.1103 - val_acc: 0.9962\n",
      "Epoch 17/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0977 - acc: 0.9990 - val_loss: 0.0908 - val_acc: 0.9981\n",
      "Epoch 18/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0830 - acc: 0.9994 - val_loss: 0.0798 - val_acc: 0.9981\n",
      "Epoch 19/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0740 - acc: 0.9998 - val_loss: 0.0716 - val_acc: 0.9981\n",
      "Epoch 20/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.0703 - acc: 0.9983 - val_loss: 0.0699 - val_acc: 0.9981\n",
      "Epoch 21/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0671 - acc: 0.9998 - val_loss: 0.0657 - val_acc: 0.9981\n",
      "Epoch 22/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0584 - acc: 0.9998 - val_loss: 0.0553 - val_acc: 0.9981\n",
      "Epoch 23/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9981\n",
      "Epoch 24/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9981\n",
      "Epoch 26/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9981\n",
      "Epoch 27/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9981\n",
      "Epoch 28/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9981\n",
      "Epoch 29/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9981\n",
      "Epoch 30/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9962\n",
      "Epoch 31/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0520 - acc: 0.9966 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0440 - acc: 0.9990 - val_loss: 0.0364 - val_acc: 0.9981\n",
      "Epoch 33/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0330 - acc: 0.9981 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0284 - acc: 0.9994 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0290 - acc: 0.9979 - val_loss: 0.0303 - val_acc: 0.9962\n",
      "Epoch 36/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0343 - acc: 0.9987 - val_loss: 0.0264 - val_acc: 0.9981\n",
      "Epoch 37/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0416 - acc: 0.9973 - val_loss: 0.0453 - val_acc: 0.9906\n",
      "Epoch 38/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0459 - acc: 0.9954 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0293 - acc: 0.9987 - val_loss: 0.0437 - val_acc: 0.9981\n",
      "Epoch 40/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1089 - acc: 0.9903 - val_loss: 0.3686 - val_acc: 0.9698\n",
      "Epoch 41/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.9667 - acc: 0.9433 - val_loss: 0.4808 - val_acc: 0.9660\n",
      "Epoch 42/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.6134 - acc: 0.9672 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1928 - acc: 0.9981 - val_loss: 0.1907 - val_acc: 0.9981\n",
      "Epoch 44/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2014 - acc: 0.9966 - val_loss: 0.1495 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1589 - acc: 0.9981 - val_loss: 0.1389 - val_acc: 0.9981\n",
      "Epoch 46/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.1497 - acc: 0.9983 - val_loss: 0.1315 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1347 - acc: 0.9992 - val_loss: 0.1175 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1141 - acc: 0.9996 - val_loss: 0.1075 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0924 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0843 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0711 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0656 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0204 - acc: 0.9998 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0230 - acc: 0.9987 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0280 - acc: 0.9985 - val_loss: 0.0253 - val_acc: 0.9981\n",
      "Epoch 74/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0195 - acc: 0.9998 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0171 - acc: 0.9983 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0138 - acc: 0.9996 - val_loss: 0.0154 - val_acc: 0.9981\n",
      "Epoch 86/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9981\n",
      "Epoch 87/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9981\n",
      "Epoch 88/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9981\n",
      "Epoch 90/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 91/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 94/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0143 - acc: 0.9990 - val_loss: 0.0167 - val_acc: 0.9981\n",
      "Epoch 96/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0380 - acc: 0.9971 - val_loss: 0.0339 - val_acc: 0.9981\n",
      "Epoch 97/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0371 - acc: 0.9992 - val_loss: 0.0286 - val_acc: 0.9981\n",
      "Epoch 98/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0318 - acc: 0.9979 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0289 - acc: 0.9983 - val_loss: 0.0239 - val_acc: 0.9981\n",
      "Epoch 100/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0180 - acc: 0.9998 - val_loss: 0.0155 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc12c22c6d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, categorical_labels, batch_size=64, epochs=100, verbose=True, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, categorical_labels, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('traffic_light_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('traffic_light_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAD8CAYAAACchf2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc12c3dce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = random.choice(images)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
