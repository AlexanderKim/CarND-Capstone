{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno_path_box = \"./dataset/Annotations/daySequence1/frameAnnotationsBOX.csv\"\n",
    "anno_path_bulb = \"./dataset/Annotations/daySequence1/frameAnnotationsBULB.csv\"\n",
    "frames_path = \"./dataset/daySequence1/frames/\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "with open(anno_path_box) as fp:  \n",
    "    line = fp.readline()\n",
    "    line = fp.readline() # Skip header line with descriptions\n",
    "\n",
    "    while line:\n",
    "        anno_file_path = (line.strip()).split(\";\")\n",
    "        anno_file_id = anno_file_path[0].split(\"/\")[1]\n",
    "        \n",
    "        file_name = os.path.join(os.path.join(frames_path, anno_file_id))\n",
    "        \n",
    "        anno_left = int(anno_file_path[2])\n",
    "        anno_top = int(anno_file_path[3])\n",
    "        anno_right = int(anno_file_path[4])\n",
    "        anno_bot = int(anno_file_path[5])\n",
    "        \n",
    "        file = cv2.imread(file_name)\n",
    "        file = cv2.cvtColor(file, cv2.COLOR_BGR2RGB);\n",
    "        crop = file[anno_top:anno_bot, anno_left:anno_right]\n",
    "        resized = cv2.resize(crop, (32, 64))\n",
    "        \n",
    "        images.append(resized)\n",
    "        labels.append(\n",
    "            {'go': 0,\n",
    "             'goLeft': 0,\n",
    "             'goForward': 0,\n",
    "             'warning': 1,\n",
    "             'warningLeft': 1,\n",
    "             'stop': 2,\n",
    "             'stopLeft': 2\n",
    "            }[anno_file_path[1]]\n",
    "        )\n",
    "        \n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(images), np.array(labels), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 5293\n",
      "Number of testing examples = 2607\n",
      "Image data shape = (64, 32, 3)\n",
      "Number of classes = 3\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import losses, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_labels = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 32, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "#Dropout(0.8)\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(MaxPooling2D(2,2))\n",
    "Dropout(0.5)\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='random_uniform', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = losses.categorical_crossentropy\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4763 samples, validate on 530 samples\n",
      "Epoch 1/100\n",
      "4763/4763 [==============================] - 1s 283us/step - loss: 2.9407 - acc: 0.8511 - val_loss: 2.3516 - val_acc: 0.8887\n",
      "Epoch 2/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 1.3578 - acc: 0.9425 - val_loss: 0.5656 - val_acc: 0.9566\n",
      "Epoch 3/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.4689 - acc: 0.9954 - val_loss: 0.4202 - val_acc: 0.9981\n",
      "Epoch 4/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.3882 - acc: 0.9994 - val_loss: 0.3577 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.3383 - acc: 0.9981 - val_loss: 0.3127 - val_acc: 0.9981\n",
      "Epoch 6/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.2937 - acc: 0.9981 - val_loss: 0.2715 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2529 - acc: 0.9998 - val_loss: 0.2349 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2201 - acc: 0.9998 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1922 - acc: 0.9998 - val_loss: 0.1794 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1678 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1470 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2524 - acc: 0.9864 - val_loss: 0.1837 - val_acc: 0.9981\n",
      "Epoch 13/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1673 - acc: 0.9971 - val_loss: 0.1484 - val_acc: 0.9981\n",
      "Epoch 14/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1761 - acc: 0.9958 - val_loss: 0.1344 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.1346 - acc: 0.9985 - val_loss: 0.1170 - val_acc: 0.9981\n",
      "Epoch 16/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1109 - acc: 0.9990 - val_loss: 0.1103 - val_acc: 0.9962\n",
      "Epoch 17/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0977 - acc: 0.9990 - val_loss: 0.0908 - val_acc: 0.9981\n",
      "Epoch 18/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0830 - acc: 0.9994 - val_loss: 0.0798 - val_acc: 0.9981\n",
      "Epoch 19/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0740 - acc: 0.9998 - val_loss: 0.0716 - val_acc: 0.9981\n",
      "Epoch 20/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.0703 - acc: 0.9983 - val_loss: 0.0699 - val_acc: 0.9981\n",
      "Epoch 21/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0671 - acc: 0.9998 - val_loss: 0.0657 - val_acc: 0.9981\n",
      "Epoch 22/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0584 - acc: 0.9998 - val_loss: 0.0553 - val_acc: 0.9981\n",
      "Epoch 23/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9981\n",
      "Epoch 24/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9981\n",
      "Epoch 26/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 0.9981\n",
      "Epoch 27/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9981\n",
      "Epoch 28/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9981\n",
      "Epoch 29/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9981\n",
      "Epoch 30/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9962\n",
      "Epoch 31/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0520 - acc: 0.9966 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0440 - acc: 0.9990 - val_loss: 0.0364 - val_acc: 0.9981\n",
      "Epoch 33/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0330 - acc: 0.9981 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0284 - acc: 0.9994 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0290 - acc: 0.9979 - val_loss: 0.0303 - val_acc: 0.9962\n",
      "Epoch 36/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0343 - acc: 0.9987 - val_loss: 0.0264 - val_acc: 0.9981\n",
      "Epoch 37/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0416 - acc: 0.9973 - val_loss: 0.0453 - val_acc: 0.9906\n",
      "Epoch 38/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0459 - acc: 0.9954 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0293 - acc: 0.9987 - val_loss: 0.0437 - val_acc: 0.9981\n",
      "Epoch 40/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1089 - acc: 0.9903 - val_loss: 0.3686 - val_acc: 0.9698\n",
      "Epoch 41/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.9667 - acc: 0.9433 - val_loss: 0.4808 - val_acc: 0.9660\n",
      "Epoch 42/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.6134 - acc: 0.9672 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.1928 - acc: 0.9981 - val_loss: 0.1907 - val_acc: 0.9981\n",
      "Epoch 44/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.2014 - acc: 0.9966 - val_loss: 0.1495 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.1589 - acc: 0.9981 - val_loss: 0.1389 - val_acc: 0.9981\n",
      "Epoch 46/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.1497 - acc: 0.9983 - val_loss: 0.1315 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1347 - acc: 0.9992 - val_loss: 0.1175 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1141 - acc: 0.9996 - val_loss: 0.1075 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "4763/4763 [==============================] - 1s 235us/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0924 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0843 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0711 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0656 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "4763/4763 [==============================] - 1s 234us/step - loss: 0.0204 - acc: 0.9998 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0230 - acc: 0.9987 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0280 - acc: 0.9985 - val_loss: 0.0253 - val_acc: 0.9981\n",
      "Epoch 74/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0195 - acc: 0.9998 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0171 - acc: 0.9983 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0138 - acc: 0.9996 - val_loss: 0.0154 - val_acc: 0.9981\n",
      "Epoch 86/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9981\n",
      "Epoch 87/100\n",
      "4763/4763 [==============================] - 1s 229us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9981\n",
      "Epoch 88/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9981\n",
      "Epoch 90/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 91/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "4763/4763 [==============================] - 1s 232us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 94/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0143 - acc: 0.9990 - val_loss: 0.0167 - val_acc: 0.9981\n",
      "Epoch 96/100\n",
      "4763/4763 [==============================] - 1s 230us/step - loss: 0.0380 - acc: 0.9971 - val_loss: 0.0339 - val_acc: 0.9981\n",
      "Epoch 97/100\n",
      "4763/4763 [==============================] - 1s 233us/step - loss: 0.0371 - acc: 0.9992 - val_loss: 0.0286 - val_acc: 0.9981\n",
      "Epoch 98/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0318 - acc: 0.9979 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0289 - acc: 0.9983 - val_loss: 0.0239 - val_acc: 0.9981\n",
      "Epoch 100/100\n",
      "4763/4763 [==============================] - 1s 231us/step - loss: 0.0180 - acc: 0.9998 - val_loss: 0.0155 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc12c22c6d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, categorical_labels, batch_size=64, epochs=100, verbose=True, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
